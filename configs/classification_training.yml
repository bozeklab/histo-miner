
# All path related parameters
# the "" quotes allow to break the line with \ properly for then loading into python
  paths:
    folders:
        main: "/home/lsancere/These/CMMC/Ada_Mount/lsancere/Data_General/histo-miner/testdataorga/tissue_analyses/"


# All not strings parameters
  parameters:
    bool:
      perform_split: False

      classification_from_allfeatures: True

      saving_classifiers:
        ridge: True

        logistic_regression: True

        random_forest: True

        xgboost: True 

        light_gbm: True 


    int:
      split_pourcentage: 15


# Classifiers parameters

  classifierparam:
    ridge:
      # For more information on the parameters check sklearn.linear_model.RidgeClassifier documentation
      # #https://scikit-learn.org/stable/modules/linear_model.html
      
      random_state: 42

      alpha:  2

      grid_dict: 
          random_state: [0, 42, 84]
          # random_state: [0, 42, 84]
          # for dev: random_state: [0]

          alpha: [0, 0.1, 0.5, 1, 2, 4, 8, 16]
          # alpha: [0, 0.1, 0.5, 1, 2, 4, 8, 16]
          # for dev: [0.5, 16]

    logistic_regression:
      # For more information on the parameters check sklearn.linear_model.LogisticRegression documentation
      # #https://scikit-learn.org/stable/modules/linear_model.html
      random_state: 42

      penalty: 'l2'

      solver: 'liblinear'
      # choice for binary classification

      multi_class: 'ovr'
      # choice for binary classification

      class_weight: 'balanced'

      grid_dict: 
          random_state: [0, 42, 84]
          # random_state: [0, 42, 84]
          # for dev: [0]

          penalty: ['l1', 'l2']
          # penalty: ['l1', 'l2']
          # for dev: ['l1', 'l2']

          solver: ['liblinear']

          multi_class: ['ovr']

          class_weight: ['balanced']


    random_forest:
      # For more information on the parameters check sklearn.linear_model.RandomForestClassifier documentation
      # #https://scikit-learn.org/stable/modules/linear_model.html
      
      random_state: 42

      n_estimators: 100
      # The number of trees in the forest.

      class_weight: 'balanced'

      grid_dict: 
          random_state: [0, 42, 84]
          # random_state: [0, 42, 84]
          # for dev: [84]

          n_estimators: [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]
          # n_estimators: [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]
          # for dev: [20, 40]

          class_weight: ['balanced']

    xgboost:
      # For more information on xgboost parameters check the documentation here:
      # #https://xgboost.readthedocs.io/en/stable/parameter.html
      # and
      # #https://xgboost.readthedocs.io/en/stable/get_started.html
      
      random_state: 42

      n_estimators: 100
      # number of boosting iterations, should be = number of trees in the forest

      learning_rate: 1

      objective: 'binary:logistic'
      # choice to take for binary classification

      grid_dict:
          random_state: [0, 42, 84]
          # random_state: [0, 42, 84]
          # for dev: [0]

          n_estimators: [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]
          # n_estimators: [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]
          # for dev: [40]
         
          learning_rate: [0.001, 0.01, 0.1, 0.8, 1, 1.2] 
          # learning_rate: [0.001, 0.01, 0.1, 0.8, 1, 1.2]  
          # for dev: [0.1]

          objective: ['binary:logistic']

    light_gbm:
      # For more information on light_gbm parameters check the documentation here:
      # #https://lightgbm.readthedocs.io/en/stable/Parameters.html
      # and
      # #https://lightgbm.readthedocs.io/en/stable/Python-Intro.html
      
      random_state: 42

      n_estimators: 100 
      # number of boosting iterations, should be = number of trees in the forest

      learning_rate: 1

      objective: 'binary'
      # choice to take for binary classification

      num_leaves: 10

      grid_dict: 
            random_state: [0, 42, 84]
            # random_state: [0, 42, 84]
            # for dev: [0]

            n_estimators: [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]
            # n_estimators: [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]
            # for dev: [60, 80]

            learning_rate: [0.001, 0.01, 0.1, 0.8, 1, 1.2]
            # learning_rate: [0.001, 0.01, 0.1, 0.8, 1, 1.2] 
            # for dev: [1, 1.2]

            objective: ['binary']

            num_leaves: [2, 5, 10, 15, 20, 40]
            # num_leaves: [2, 5, 10, 15, 20, 40]
            # for dev: [5, 10]
 
















