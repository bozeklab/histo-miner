
# All path related parameters
# the "" quotes allow to break the line with \ properly for then loading into python
  paths:
    folders:
        main: "/home/lsancere/These/CMMC/Ada_Mount/lsancere/Data_General/histo-miner/testdataorga/tissue_analyses/"


# All not strings parameters
  parameters:
    bool:
      perform_split: False

      classification_from_allfeatures: True

      saving_classifiers:
        ridge: False

        logistic_regression: False

        random_forest: True

        xgboost: True 

        light_gbm: False 


    int:
      split_pourcentage: 15


# Classifiers parameters

  classifierparam:
    ridge:
      # For more information on the parameters check sklearn.linear_model.RidgeClassifier documentation
      # #https://scikit-learn.org/stable/modules/linear_model.html
      alpha:  2

    logistic_regression:
      # For more information on the parameters check sklearn.linear_model.LogisticRegression documentation
      # #https://scikit-learn.org/stable/modules/linear_model.html
      solver: 'liblinear'
      # choice for binary classification

      multi_class: 'ovr'
      # choice for binary classification

    random_forest:
      # For more information on the parameters check sklearn.linear_model.RandomForestClassifier documentation
      # #https://scikit-learn.org/stable/modules/linear_model.html
      n_estimators: 100
      # The number of trees in the forest.

      class_weight: 'balanced'

      grid_dict: 
          n_estimators: [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]

          class_weight: ['balanced']

    xgboost:
      # For more information on xgboost parameters check the documentation here:
      # #https://xgboost.readthedocs.io/en/stable/parameter.html
      # and
      # #https://xgboost.readthedocs.io/en/stable/get_started.html
      n_estimators: 100
      # number of boosting iterations, should be = number of trees in the forest

      learning_rate: 1

      objective: 'binary:logistic'
      # choice to take for binary classification

      grid_dict:
          n_estimators: [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]

          learning_rate: [0.1, 0.8, 0.9, 1, 1.1, 1.2, 1.3] 

          objective: ['binary:logistic']

    light_gbm:
      # For more information on light_gbm parameters check the documentation here:
      # #https://lightgbm.readthedocs.io/en/stable/Parameters.html
      # and
      # #https://lightgbm.readthedocs.io/en/stable/Python-Intro.html
      n_estimators: 100 
      # number of boosting iterations, should be = number of trees in the forest

      learning_rate: 1

      objective: 'binary'
      # choice to take for binary classification

      num_leaves: 10

      grid_dict: 
            n_estimators: [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]

            learning_rate: [0.1, 0.8, 0.9, 1, 1.1, 1.2, 1.3]

            objective: ['binary']

            num_leaves: [2, 5, 10, 15, 20, 40]
 
















